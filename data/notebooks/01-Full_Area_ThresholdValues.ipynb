{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating binary images: \n",
    "\n",
    "- Before an image can be segmented a binary image is needed \n",
    "- To do this we use Otsu thresholding which finds a cut-off value for background and foreground. \n",
    "- This number is then used in the next notebooks to find porosity values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a file for the threhsold values for each sample/tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitattributes',\n",
       " '20250312_PorosityAnalysis',\n",
       " 'data',\n",
       " 'notebooks',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('../../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the module for the porosity_analysis packages  \n",
    "\n",
    "import os \n",
    "import sys \n",
    "\n",
    "Pyro_module  = '../../20250312_PorosityAnalysis/porosity_analysis'\n",
    "# Add the parent directory of Pyro_DataAnalysis to the system path\n",
    "if os.path.exists(Pyro_module) == True:\n",
    "    sys.path.insert(0, os.path.abspath(Pyro_module))\n",
    "else :\n",
    "    print('The file does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops,regionprops_table ,find_contours\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.patches as mpatches\n",
    "import imageio.v3 as iio\n",
    "\n",
    "import config \n",
    "import custom_funcs \n",
    "import image_analysis as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# to make sure the computer doesnt think you are deploying a bomb \n",
    "import PIL.Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 3019898880 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google drive location or location of the image folder\n",
    "experimental_dir = Path(config.technical_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save location\n",
    "df_save_loc = experimental_dir/'data/processed/global_threshold.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These files have been done :[]\n"
     ]
    }
   ],
   "source": [
    "## Check what has been done already: \n",
    "\n",
    "if os.path.exists(df_save_loc) == True:\n",
    "    df_done = pd.read_csv(df_save_loc)\n",
    "    ref_im_done = list(df_done['ref_im'])\n",
    "else:\n",
    "    df_done = pd.DataFrame(columns= ['ref_im','date','Material','Designation','Otsu']) # Create Dataframe with the column headings\n",
    "    ref_im_done = list(df_done['ref_im'])\n",
    "print(f'These files have been done :{ref_im_done}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing in Fiji\n",
    "\n",
    "#### Before anything can happen:\n",
    "- The images should be cropped to just the relevant area\n",
    "- Saved all images in .png in the processed folder \n",
    "- Put full images for thresholding in thresholding folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference image for thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_im_dir_temp = experimental_dir/'Raw/png' # the place all the raw images \n",
    "ref_im_dir = [file for file in os.listdir(ref_im_dir_temp) if file.endswith('.png')] # look only at .png \n",
    "ref_im_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns= ['ref_im','date','Material','Designation','Otsu']) # Create Dataframe with the column headings for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\AppData\\Local\\Temp\\ipykernel_14768\\2015535755.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{'ref_im': ref_im, 'date': date, 'Material': Material, 'Designation': Designation, 'Otsu': Otsu}])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ref_im in os.listdir(ref_im_dir):\n",
    "    parts = ref_im.split(\"_\")\n",
    "\n",
    "    if ref_im in ref_im_done:\n",
    "        continue\n",
    "    \n",
    "    if len(parts) >= 3: #check if the filename is in the correct format.\n",
    "            date = parts[0]\n",
    "            Material = parts[1]\n",
    "            Designation = parts[2]\n",
    "\n",
    "            # load image\n",
    "            ref_img = os.path.join(ref_im_dir, ref_im)\n",
    "            \n",
    "            im = custom_funcs.load_image(ref_img)\n",
    "            ## check if an image is greyscale\n",
    "            gs_img = custom_funcs.is_greyscale(im)\n",
    "            \n",
    "            # Clean image \n",
    "            image_blur = gaussian(gs_img,2)\n",
    "            # Get threshold value \n",
    "            Otsu = threshold_otsu(image_blur)\n",
    "            after_Otsu = image_blur < Otsu\n",
    "\n",
    "\n",
    "            # Append to DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame([{'ref_im': ref_im, 'date': date, 'Material': Material, 'Designation': Designation, 'Otsu': Otsu}])], ignore_index=True)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(df_save_loc, index=False, header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_im</th>\n",
       "      <th>date</th>\n",
       "      <th>Material</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Otsu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ref_im, date, Material, Designation, Otsu]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myimage_analysis1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
